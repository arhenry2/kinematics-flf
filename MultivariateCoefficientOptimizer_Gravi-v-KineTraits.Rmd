---
title: "MultivariateCoefficientOptimizer_Gravi-v-KineTraits"
author: "Ashley Henry, Nathan Miller"
date: "11/17/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(plotly)
library(tidyverse)
library(readr)
library(rowr)
require(reshape2)
library(dplyr)
library(pracma)
library(data.table)
library(qtl2)
library(CCA)
```

```{r metric-function}

metric <- function(mappedList1, mappedList2){
  # Does correlation
  correlation = cor(mappedList1, mappedList2, use = "complete.obs")
  return(correlation)
}

# Try this out:
# mappedList1 = runif(10)
# mappedList2 = runif(10)
# metric(mappedList1, mappedList2)
```

```{r predictor-function}

predictor_norm <- function(M, v){
  # v = v / norm(as.matrix(v))
  v = v / norm(v)
  predicted = M%*%v
  return(predicted)
}

predictor <- function(M, v){
  predicted = M%*%v
  return(predicted)
}

# Try this out:
# pmat = matrix(c(1:4), ncol = 4, nrow = 162)
# pvec = c(1, 1, 1, 1)
# ppre = predictor(pmat, pvec)
# 
# smat = matrix(c(1:2), ncol = 2, nrow = 162)
# svec = c(1, 1)
# spre = predictor(smat, svec)
```

```{r QTLMapping-function}
# Ash Note: This works for CT being there, but we need to redo this so that we enter in our own phenotype data
## That way we don't have to load it into the .json file
## So, make a genotype file with the marker data (& location...?)

mapper <- function(data_in_csv, ct){
  # Inserted pieces of QTLCode.R (see QTLCode.R for annotations!)
  # Have it return peaks from 0 permutations to test
  
  g1 <- do.call("cbind", ct$geno) 
  map <- insert_pseudomarkers(ct$gmap, step = 2.5, stepwidth = "max")
  pr <- calc_genoprob(ct, map, error_prob = 0.002)
  m1 <- maxmarg(pr)
  xo1 <- count_xo(m1) 
  k_loco <- calc_kinship(pr, "loco") 
  x = dim(ct$pheno)[2]
  out <- scan1(pr, ct$pheno[,c(1:x)], k_loco, cores = 4)
  # print(out)
  nperm = 1000 # changed n_perm = 10000 from 1000 (5.9.2021)
  operm <- scan1perm(pr[,1:5], ct$pheno[,c(1:x)], k_loco[1:5], addcovar = NULL,
                   Xcovar = NULL, intcovar = NULL, weights = NULL, reml = TRUE,
                   model = "normal", n_perm = nperm, perm_Xsp = FALSE,
                   perm_strata = NULL, chr_lengths = NULL, cores = 4)

  sig <- summary(operm, alpha = c(0.05)) # Need this? 
  return(out)
}

## Try this out & plot LOD scores:
# setwd("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL")
# CT <- read_cross2("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/CvixLer.working.json")
# CT
# CT$pheno <- tipAngle # change phenotype data for mapper()
# map = mapper(pheno, CT)
# x_axis = c(1:340)
# plot(x_axis, map[,1]) # plot 1st column of LOD scores by marker

```

```{r qtl-function-no-CT-loading_IN-PROGRESS}
#######################################################
##### Testing qtl function so can use without CT ######
# Gave up on this 2021-11-29 b/c above function works #
#######################################################

CT <- read_cross2("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/CvixLer.working.json")
geno <- read_csv2("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/ALFP_geno.csv")
gmap <- read_csv("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/ALFP_gmap.csv")
pmap <- read_csv2("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/ALFP_geno.csv")
# pheno = "phenotypes by RIL" #(2021_11_22_growthCurveDescriptors_Averaged-pos-to-3000.csv)
pheno1 <- runif(162)
pheno2 <- runif(162)
RIL <- c(1:162)
pheno <- matrix(data = cbind(RIL, pheno2), nrow = 162, ncol = 2) # phenotype (try 1st w/ a random set of numbers & get no peaks)
# If matrix() ->
# Note:
##  "alleles": ["L", "C"], "genotypes": {"L": 1, "C": 2}

mapperTMP <- function(gmap, genomap, pheno, CT){
  # Inserted pieces of QTLCode.R (see QTLCode.R for annotations!)
  # Have it return peaks from 0 permutations

  g1 <- do.call("cbind", geno)
  map <- insert_pseudomarkers(CT$gmap, step = 2.5, stepwidth = "max")
  pr <- calc_genoprob(CT, map, error_prob = 0.002)
  m1 <- maxmarg(pr)
  xo1 <- count_xo(m1)
  k_loco <- calc_kinship(pr, "loco")
  out <- scan1(pr, pheno, k_loco, cores = 4)
  print(out)
  nperm = 1 # changed n_perm = 10000 from 1000 (5.9.2021)
  operm <- scan1perm(pr[,1:5], pheno[,c(1)], k_loco[1:5], addcovar = NULL,
                   Xcovar = NULL, intcovar = NULL, weights = NULL, reml = TRUE,
                   model = "normal", n_perm = nperm, perm_Xsp = FALSE,
                   perm_strata = NULL, chr_lengths = NULL, cores = 4)

  sig <- summary(operm, alpha = c(0.05)) # Need this?
  return(out)
}

map = mapperTMP(gmap, genomap, pheno, CT)
x = c(1:340)
plot(x,map)
```

```{r putting-it-all-together}
REGR = read_csv("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/2021_04_18_growthCurveDescriptors_Averaged-FINAL.csv")
REGR = data.matrix(REGR)
tipAngle = read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL1_tipAngle_PCScores.csv")
tipAngle = data.matrix(tipAngle)

# Overall goal is to calculate the sum of correlations below: 
## Note: Test alpha as c(1,1,1,1) (check by summing row 1); test alpha with c(0.25, 0.25, 0.25, 0.25) (check by taking average of row 1)
# metric(predictor(REGR,c(0.25,0.25,0.25,0.25)), predictor(tipAngle, beta)) + metric(mapper(G,predictor(REGR, alpha)), mapper(G,predictor(tipAngle, beta)))

# T1 for predicting and calculating correlation
T1 <- function(s){
  alpha = s[1:4]
  beta = s[5:6] # specify this as "end of s" later
  A = metric(predictor_norm(REGR, alpha), predictor_norm(tipAngle, beta))
  A = as.vector(A)
}

T1(c(1,1,1,1,2,2)) # need 6 because we have 6 total phenotypes (4 kine traits + 2 PC scores of gravi data)
xSol1 = fminsearch(T1, runif(6), minimize = FALSE, maxiter = 100) # with min = FALSE, it searches for maximum

# T2 for mapping and calculating correlation
setwd("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL")
CT <- read_cross2("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/CvixLer.working.json")
CT

T2 <- function(p){
  alpha = p[1:4]
  beta  = p[5:7] # specify this as "end of p" later
  
  # Below is original when had mappers together & didn't include both phenotypes  
  # B = metric(mapper(G,predictor_norm(REGR, alpha)), mapper(G,predictor_norm(tipAngle, beta)))

  # Load regr and tip angles
  ct   <- read_cross2("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/CvixLer.working.json")
  regr <- read_csv("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/2021_04_18_growthCurveDescriptors_Averaged-FINAL.csv")
  tagl <- read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL1_tipAngle_PCScores.csv")
  regr = data.matrix(regr)
  tagl = data.matrix(tagl)

  
  Z = metric(predictor_norm(REGR, alpha), predictor_norm(tipAngle, beta))
  Z = as.vector(Z)
  
  # Phenotype = REGR for 1st mapper
  ct$pheno <- regr
  A = mapper(predictor_norm(regr, alpha), ct)
  
  # Phenotype = tipAngle for 2nd mapper
  ct$pheno <- tagl
  B = mapper(predictor_norm(tagl, beta), ct)
  C = metric(A, B)
  C = as.vector(C)
  D = C + Z
  print(D)
}

xSol2 = fminsearch(T2, runif(6), minimize = FALSE, maxiter = 100)
pp    = xSol2$xmin
optA  = pp[1:4]
optB  = pp[5:7]

optAA  = predictor_norm(REGR, optA)
optBB  = predictor_norm(tipAngle, optB)

plot(optAA, optBB)
data = data.frame(cbind(optAA, optBB))
ggplot(data, aes(optAA)) +
  geom_point(aes(y=optBB), colour = "blue")

optCC = mapper(predictor_norm(REGR, optA), CT)
optDD = mapper(predictor_norm(tipAngle, optB), CT)

x_axis = c(1:340)
plot(x_axis, optCC[,1]) # plot 1st column of LOD scores by marker

data2 = data.frame(cbind(x_axis, optCC[,1], optDD[,1]))
ggplot(data2, aes(x_axis)) + 
  # geom_point(aes(y = optCC[,1]), colour = "red") +
  geom_point(aes(y = optDD[,1]), colour = "blue")

```

```{r TO-DO-LIST}
### TO DO LIST | Made 2021-11-30 ###
## Need to save 2 different LOD score datasets!!!
# need loop to have it start at 100 random start values & pick the best solution
## Why is the convergence 0? 
## Check out output to understand it (tolerance, maxiter, max etc.)

## After chatting briefly with Nathan on 20 December 2021, this is my next step:
# Use predictor_norm to get "new" values for kine traits (new alphas) & "new" values for PC of tipAngles (new betas)
# Scatterplot these new values & compare to scatterplots of original kine traits & PCs
```

``` {r actually-putting-it-all-together}
# T3 combines the 2 datasets below to see which "recipe" gives the best correlation between these:
## raw REGR & tipAngle PC scores data
REGR = read_csv("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/2021_04_18_growthCurveDescriptors_Averaged-FINAL.csv")
REGR = data.matrix(REGR)
tipAngle = read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL1_tipAngle_PCScores.csv")
tipAngle = data.matrix(tipAngle)

# Now try CCA with RIL1 and RIL2 tip angle datasets
## Loading in PC scores from RIL1 & RIL2 tip angle datasets
RIL1TipAngles = read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL1_tipAngle_PCScores.csv")
RIL1TipAngles = data.matrix(RIL1TipAngles)
RIL2TipAngles = read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL2_tipAngle_PCScores.csv")
RIL2TipAngles = data.matrix(RIL2TipAngles)

T3 <- function(s){
  # params = s[1:4]
  # scrs   = s[5:7]
  
  # Pc = predictor_norm(REGR, params)
  # Sc = predictor_norm(tipAngle, scrs)
  
  params = s[1:3]
  scrs   = s[4:6]
  Pc = predictor_norm(RIL1TipAngles, (params))
  Sc = predictor_norm(RIL2TipAngles, as.numeric(as.vector(scrs)))
  p  = as.vector(metric(Pc, Sc))
}

# pinit = runif(7)
pinit = runif(6)
topt  = fminsearch(T3, pinit, minimize = FALSE, maxiter = 10000)
pp    = topt$xmin
optJ  = pp[1:3] # 1:4
optK  = pp[4:6] # 5:7

# Transform REGR & tipAngle data by the "recipe" from fminsearch()
optJJ = predictor_norm(RIL1TipAngles, optJ)
optKK = predictor_norm(RIL2TipAngles, optK)
copt  = metric(optJJ,optKK) # 64 = correlation b/w RIL1 & RIL2 tip angle datasets with CCA...

# Plotting new REGR & tipAngle data to visualize correlation
# ttl  = sprintf("Transformed Tip Angle PCs and REGR Traits Data [corr = %f]", copt)
ttl  = sprintf("Transformed Tip Angles of RIL1 and RIL2 Datasets [corr = %f]", copt)
data = data.frame(cbind(optJJ, optKK))
ggplot(data, aes(x = optJJ, y = optKK)) +
  geom_point(aes(y = optKK), colour = "blue") +
  # xlab("REGR Trait Data") +
  # ylab("Tip Angle PC Scores Data") +
  xlab("RIL1 Tip Angle PC Scores") +
  ylab("RIL2 Tip Angle PC Scores") +
  ggtitle(ttl) +
  stat_summary(fun.data = mean_cl_normal) + 
  geom_smooth(method = 'lm') +
  theme_bw()

```

```{r CCA-on-qtl-mapping}
metric(optJJ, optKK) # -0.04825338
metric(REGR[,1], tipAngle[,1]) # 0.2065649
metric(REGR[,4], tipAngle[,1]) # 0.2065649


# T4 combines the 2 datasets below to see which "recipe" gives the best correlation between these:
## LOD scores of mapped, raw REGR & tipAngle PC scores data
T4 <- function(s){
  # 
  # alpha = s[1:4]
  # beta = s[5:7] # specify this as "end of s" later
  
  # csv files for mapper() & in matrix format
  CT   <- read_cross2("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/CvixLer.working.json")
  REGR <- read_csv("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/2021_04_18_growthCurveDescriptors_Averaged-FINAL.csv")
  tipAngle <- read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL1_tipAngle_PCScores.csv")
  REGR = data.matrix(REGR)
  tipAngle = data.matrix(tipAngle)
  
  # Phenotype = REGR for 1st mapper
  CT$pheno <- REGR
  J = mapper(REGR, CT)

  # Phenotype = tipAngle for 2nd mapper
  CT$pheno <- tipAngle
  K = mapper(tipAngle, CT)
  
  # Find correlations between REGR & tipAngle LOD scores
  L = metric(J, K)
  L = as.vector(L)
  
  # # Add correlations
  # P = H + L
  # print(P)
}

recipe_T4 = fminsearch(T4, runif(7), minimize = FALSE, maxiter = 100)
pp = recipe_T4$xmin
optA = pp[1:4]
optB  = pp[5:7]

# Transform REGR & tipAngle data by the "recipe" from fminsearch()
CT <- read_cross2("~/Desktop/QTL_AnalysisMaterials/Ashley_QTL/CvixLer.working.json")
CT$pheno <- REGR
optAA  = mapper(predictor_norm(REGR, optA), CT)
CT$pheno <- tipAngle
optBB  = mapper(predictor_norm(tipAngle, optB), CT)

# Plot new LOD scores
x_axis = c(1:340)
row.names(optAA) <- c(1:340)
row.names(optBB) <- x_axis
data_T4 = data.frame(cbind(optAA, optBB))

ggplot(data_T4, aes(x = x_axis)) +
  geom_line(aes(y = maxREGR), colour = "blue") +
  geom_line(aes(y = posMaxREGR), colour = "cyan") +
  geom_line(aes(y = overallGrowthRate), colour = "cornflowerblue") +
  geom_line(aes(y = growthZoneWidth), colour = "aquamarine3") +
  
  geom_line(aes(y = RIL1.TipAngle_PC1), colour = "red") +
  geom_line(aes(y = RIL1.TipAngle_PC2), colour = "brown1") +
  geom_line(aes(y = RIL1.TipAngle_PC3), colour = "darkred") +

  # ADD A LINE SO WE KNOW WHAT'S SIGNIFICANT!!!

  xlab("Marker Locations along Genome") +
  ylab("LOD Score") +
  ggtitle("Transformed LOD Scores of Tip Angle PCs and REGR Traits Data") +
  theme_bw()
```

```{r check-using-R's-CCA}
# Can test if fminsearch went well by finding the true values of alpha and beta using Canonical Correlation Analysis
## Helpful site: https:// stats.idre.ucla.edu/r/dae/canonical-correlation-analysis/
CCA = cc(REGR, tipAngle)
CCA = cc(RIL1TipAngles, RIL2TipAngles)
# Maximized coefficients from own code with fminsearch():
pp
optJ  = pp[1:3] # 1:4
optK  = pp[4:6] # 5:7
optJJ = optJ/norm(optJ, type = "2")
optKK = optK/norm(optK, type = "2")

# Maximized coefficients from CCA()
CCA$cor
CCA$scores$xscores[,1]
CCA$scores$yscores[,1]
cor(CCA$scores$xscores[,1], CCA$scores$yscores[,1]) # check that correlation matches my cca process' correlation
cor(CCA$scores$xscores[,2], CCA$scores$yscores[,2]) # this isn't great, so we'll just focus on the 1st column

optA = CCA$xcoef[,1]
optB = CCA$ycoef[,1]
optAA = optA/norm(optA, type = "2")
optBB = optB/norm(optB, type = "2") # type 2 = euclidian normalization


# 18 Jan 2021
## Compared optJJ & optKK (my version of CCA) to make sure they match optAA & optBB (R version of CCA)
## They match! :)

```

```{r own-PCA-in-R}
### Note: This is copied from gravitropismAssay.Rmd on 1-19-2022 so that I can grab the PCA results from the full output of prcomp()
## Also, if tipAngles doesn't run, go into your Finder and download that file from ~the cloud~

# Load in Candace's tip angle data (for datasets RIL1 and RIL2)
tipAngles = read.csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/RIL2_GravitropismData_tipAngles.csv") 
scores <- prcomp(tipAngles[,c(2:242)], center = TRUE, scale. = FALSE)
# This matches 

scores
indexNames = tipAngles$RIL
n = 3 # was 7 in gravitropismAssay.Rmd
PCScores_Ashley = matrix(NA, 162, n)
UU = matrix(NA, 162, 241)
for (i in 1:n){
  for (j in 1:162){ # 162 = number of RILs
    index = which(indexNames == j)
    PCScores_Ashley[j,i] = mean(scores$x[index,i])
    UU[j,] = as.numeric(tipAngles[index,c(2:242)] %>% summarise_if(is.numeric, mean))
  }
}

RIL = c(1:162)
PCScores_Ashley = cbind(RIL, PCScores_Ashley)
```

```{r tipAngle-sweep}
# Started 19 Jan 2021 with Nathan
# tipAngle = read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL1_tipAngle_PCScores.csv")
# tipAngle = data.matrix(tipAngle)
# newTipAngleData = predictor(as.matrix(tipAngle), as.vector(optAA))

# Doing same as above, but with RIL2 dataset:
RIL2_PCScores = read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL1_tipAngle_PCScores.csv")
RIL2_PCScores = data.matrix(RIL2_PCScores)
# newTipAngleData = predictor(as.matrix(tipAngle), as.vector(optAA))
newRIL2_PCScores = predictor(as.matrix(RIL2_PCScores), as.vector(optBB))

# estimate the % var explained by solution vector
var = var(tipAngle[,1]) + var(tipAngle[,2]) + var(tipAngle[,3])

var2 = var(newRIL2_PCScores)
var2/var
# Conclusion: 21% of variance is explained by the newTipAngleData

# St Dev
sqrt(var2) # st dev of newTipAngleData = 63.69877


# Now using PCA values from the code chunk above
# tAngle = read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL1_tipAngle_PCScores.csv")
# tAngle = t(tAngle) # Makes this 3 x 162
tAngle = read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL2_tipAngle_PCScores.csv")
tAngle = t(tAngle) # Makes this 3 x 162

eta = scores$rotation[,1:3] # Eigen vectors from PCA output
# GET SCORES FROM 'own-PCA-in-R' CODE CHUNK!!! (change when change datasets!)

tipAngles = read.csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/RIL2_GravitropismData_tipAngles.csv")
uta = tipAngles %>% summarise_if(is.numeric, mean)
uta = t(tipAngles %>% summarise_if(is.numeric, mean))
uta = uta[2:242,] # avg of all RILs' tip angles at all time points

# Grab one example of a tipangle curve
tipAngles_Ex = tipAngles %>%
  group_by(RIL) %>%
  # select(-Index_RIL, -Index_cam, -Index_middle, -RIL_partName, -RIL_fullName) %>%
  summarise_each(funs(mean(., na.rm = TRUE))) # Added na.rm so that averages didn't calc in the NAs for the mean
tipAngles_Ex = t(tipAngles)
tipAngles_Ex = tipAngles_Ex[2:242,] # removes RIL row from dataframe


# tipAngle = tipAngle[,1] 
G = predictor(eta, as.numeric(as.vector(tAngle[,1]))) + uta # grabbing one RIL as example to compare to G
plot(G) # plot of estimated tip angle curve from eigen vectors & avg tip angles
plot(uta) # plot of averaged tip angle over time (avg of all RILs)
plot(tipAngles_Ex[,1]) # plot of tip angle over time of avg RIL1 (or whichever RIL used in G)

# -65, +65, & one in between those (b/c 65 is about our variance calc'd earlier)
# G_2 = predictor(eta, 65*as.numeric(as.vector(optBB))) + uta
# plot(G_2)
# G_3 = predictor(eta, -65*as.numeric(as.vector(optBB))) + uta
# plot(G_3)
G_2 = predictor(eta, 54*as.numeric(as.vector(optBB))) + uta
plot(G_2)
G_3 = predictor(eta, -54*as.numeric(as.vector(optBB))) + uta
plot(G_3)
# add 3 more equidistant points b/w -65 & +65
G_4 # etc...

# Find a way to combine these plots!
## This is copied from some above code chunk, update this to plot tip angle curves
# ttl  = sprintf("____ [corr = %f]", copt)

x_axis = c(1:241)
data = data.frame(cbind(x_axis, G, G_2, G_3))
ggplot(data, aes(x = x_axis, y = V2)) +
  geom_point(aes(y = V2), colour = "blue") + # normal tip angle curve
  geom_point(aes(y = V3), colour = "dark blue") + # tip angle curve with highest variance
  geom_point(aes(y = V4), colour = "light blue") + # tip angle curve with lowest variance
  xlab("Timepoints (every 2 min)") +
  ylab("Tip Angle") +
  # ggtitle(ttl) +
  ggtitle("RIL2 | Light = -65, Blue = avg, Dark = +65") + 
  theme_bw()


```

```{r email-from-Nathan}
# Ok, here is a longer reasoning. :-) The mean of the data should be between the lower and upper bound (at least I think it should be).  
# This is why I am expecting something to be wrong with the sweeps and the eigen vectors.
# 
# X1 = data set 1
# X2 = data set 2
# X1_x = xth trial from data set 1
# X2_x = xth trial from data set 2
# E1 = eigenvectors/rotations 1
# E2 = eigenvectors/rotations 2
# U1 = mean 1
# U2 = mean 2
# S1 = scores 1
# S2 = scores 2
# S1_x = xth score from set 1
# S2_x = xth score from set 2
# V1 = variance 1 of S1
# V2 = variance 2 of S2
# L1 = solution vector 1 from CCA 
# L2 = solution vector 2 from CCA
# 
# for sweeps:
# graph1_upper = U1 + E1*L1*V1
# graph1_mean = U1 + E1*L1*0
# graph1_lower = U1  -  E1*L1*V1
# 
# graph2_upper = U2 + E2*L2*V2
# graph2_mean = U2 + E2*L2*0
# graph2_lower = U2  -  E2*L2*V2
# 
# You could do some tests...like
# Y1_x = E1*S1_x + U1
# where Y1_x is the estimate of X1_x.  
# Plot Y1_x and X1_x to see how they look.

```

```{r final-tip-angle-sweeps}
# To match code from Nathan's email (above), I'm going to use this code block to paste various copied code from above

# Loading in datasets/materials
X1 = read.csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/RIL1_GravitropismData_tipAngles.csv") # dataset 1
X2 = read.csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/RIL2_GravitropismData_tipAngles.csv") # dataset 2

# Average tip angles by RIL before grabbing a trial from the datasets
X1_RILavg = X1 %>%
  group_by(RIL) %>%
  summarise_each(funs(mean(., na.rm = TRUE)))
X2_RILavg = X2 %>%
  group_by(RIL) %>%
  summarise_each(funs(mean(., na.rm = TRUE)))
X1_x = t(X1_RILavg[1,2:242]) # xth trial from dataset 1
X2_x = t(X2_RILavg[1,2:242]) # xth trial from dataset 2

# Eigenvectors/rotations for each dataset
X1_scores <- prcomp(X1[,c(2:242)], center = TRUE, scale. = FALSE) # PCA of X1 dataset
X2_scores <- prcomp(X2[,c(2:242)], center = TRUE, scale. = FALSE) # PCA of X2 dataset
E1 = X1_scores$rotation[,1:3] # Eigenvectors/rotations for dataset 1
E2 = X2_scores$rotation[,1:3] # Eigenvectors/rotations for dataset 2

# Average tip angles for each dataset
U1 = t(X1 %>% summarise_if(is.numeric, mean))
U1 = U1[2:242,] # avg of all RILs' tip angles at all time points
U2 = t(X2 %>% summarise_if(is.numeric, mean))
U2 = U2[2:242,] # avg of all RILs' tip angles at all time points

# PC Scores for each dataset
S1 = read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL1_tipAngle_PCScores.csv")
S1 = data.matrix(S1)
S2 = read_csv("~/Desktop/GravitropismAssay/TipAngle-Parameters-KinematicTraits_Data/2021-11-30_RIL2_tipAngle_PCScores.csv")
S2 = data.matrix(S2)

S1_x = S1[,1] # xth score from dataset 1
S2_x = S2[,1] # xth score from dataset 2

# Variance of each dataset's PC Scores
V1 = var(S1) # variance of dataset 1's PC scores
V2 = var(S2) # variance of dataset 2's PC scores
V1 = V1[1,] # just variance of PC 1
V2 = V2[1,] # just variance of PC 1

# Solution vector ("recipe") for each dataset
CCA = cc(S1, S2)
L1 = CCA$xcoef[,1] # solution vector ("recipe") 1 from CCA 
L2 = CCA$ycoef[,1] # solution vector ("recipe") 2 from CCA 
L1_normalized = optA/norm(optA, type = "2") # type 2 = euclidian normalization
L2_normalized = optB/norm(optB, type = "2") # type 2 = euclidian normalization
```

```{r actual-final-sweeps}
# For Sweeps:
graph1_upper = U1 + E1*as.vector(L1)*V1
graph1_mean  = U1 + E1*as.vector(L1)*0
graph1_lower = U1 - E1*as.vector(L1)*V1
x_axis = c(1:241)
graph1 = data.frame(cbind(x_axis, graph1_upper[,1], graph1_mean[,1], graph1_lower[,1])) # combine PC1 data to graph
ggplot(graph1, aes(x = x_axis)) +
  geom_line(aes(y = V2), colour = "dark blue") +
  geom_point(aes(y = V3), colour = "blue") +
  geom_line(aes(y = V4), colour = "light blue") +
  xlab("Time (per 2 minutes)") +
  ylab("Tip Angle") +
  ggtitle("RIL1 Dataset Tip Angle Sweeps") +
  theme_bw()

graph2_upper = U2 + E2*as.vector(L2)*V2
graph2_mean  = U2 + E2*as.vector(L2)*0
graph2_lower = U2 - E2*as.vector(L2)*V2
x_axis = c(1:241)
graph2 = data.frame(cbind(x_axis, graph2_upper[,1], graph2_mean[,1], graph2_lower[,1])) # combine PC1 data to graph
ggplot(graph2, aes(x = x_axis)) +
  geom_line(aes(y = V2), colour = "dark blue") +
  geom_line(aes(y = V3), colour = "blue") +
  geom_line(aes(y = V4), colour = "light blue")  +
  xlab("Time (per 2 minutes)") +
  ylab("Tip Angle") +
  ggtitle("RIL2 Dataset Tip Angle Sweeps") +
  theme_bw()



# You could do some tests...like:
Y1_x = E1*as.vector(S1_x) + as.vector(U1)
# where Y1_x is the estimate of X1_x.
# Plot Y1_x and X1_x to see how they look.
plot(Y1_x[,1], X1_x)
data = data.frame(cbind(x_axis, Y1_x, X1_x))
ggplot(data, aes(x = x_axis)) +
  geom_line(aes(y = X1_x), colour = "red") + 
  geom_point(aes(y = Y1_x[,1])) +
  # geom_point(aes(y = Y1_x[,2])) +
  # geom_point(aes(y = Y1_x[,3])) +
  xlab("Time (per 2 minutes)") +
  ylab("Tip Angle") +
  ggtitle("Comparing estimate vs true trial (Black = estimate, Red = trial of RIL1)") +
  theme_bw()

```



